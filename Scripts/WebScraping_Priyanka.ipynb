{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "13b00fe3-b299-4ebb-ae5f-d6f149aeff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953afb65-6cba-42d8-8aeb-d98bf105ee66",
   "metadata": {},
   "source": [
    "Start by performing a GET request on the url above and convert the response into a BeautifulSoup object.\n",
    "a. Use the .find method to find the tag containing the first job title (\"Senior Python Developer\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5fdc1419-ae48-4494-9e3c-4f5162cc39e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://realpython.github.io/fake-jobs/'\n",
    "response = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f6223b2a-1407-4ead-8e81-047347138dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get('https://realpython.github.io/fake-jobs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "42548497-53a6-4d5a-ba93-ef8068127959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4c717bcb-8f0a-4dbb-a435-29432c2578a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BS(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "525540cd-79f4-40dc-ba79-02c18f3e5a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Senior Python Developer'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.findAll('h2')[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f06fb8e-2ac9-4658-a59d-f957bc141231",
   "metadata": {},
   "source": [
    "b. Now, use what you did for the first title, but extract the job title for all jobs on this page. Store the results in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "2b1092a1-60f2-4005-a080-979fab61345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles=soup.findAll('h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "9d22c0c1-02a9-4811-86d3-55d24af6ff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = [job.get_text() for job in job_titles]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f434ece4-4d84-4022-93d5-175622bbaf0a",
   "metadata": {},
   "source": [
    "Finally, extract the companies, locations, and posting dates for each job. For example, the first job has a company of \"Payne, Roberts and Davis\", \n",
    "a location of \"Stewartbury, AA\", and a posting date of \"2021-04-08\". Ensure that the text that you extract is clean, meaning no extra spaces \n",
    "or other characters at the beginning or end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "94f5bad9-22d2-4f89-b319-a9fb2328b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_company=soup.findAll('h3')\n",
    "jobs_company = [job.get_text() for job in job_company]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebef842f-e04b-4eb3-a968-0882e1eb201a",
   "metadata": {},
   "source": [
    "job_location=soup.findAll('p')\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "d0a21519-dbc4-44f6-9856-b20b3b5f0b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_time=soup.findAll('time')\n",
    "job_time = [job.get_text() for job in job_time]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5561099-5f81-43c4-b84f-634407f4b123",
   "metadata": {},
   "source": [
    "d. Take the lists that you have created and combine them into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b1d31e43-c633-4d1f-b72c-b836f5d0f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_listings = pd.DataFrame({'Job Title': jobs,'Location': jobs_company,'Date':job_time,'Apply_here':urls})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6931cee0-a72a-4fda-b21e-b60bc3bf5f66",
   "metadata": {},
   "source": [
    "2 Next, add a column that contains the url for the \"Apply\" button. Try this in two ways.\n",
    "a. First, use the BeautifulSoup find_all method to extract the urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5b6968a9-c352-47c2-b690-bba7caacb756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_link=soup.findAll('a',href=True)\n",
    "job_link = [job.get_text() for job in job_link]\n",
    "len(job_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c391def-abb1-41e0-9ada-a9330dc9d521",
   "metadata": {},
   "source": [
    "urls = []\n",
    "for link in soup.find_all('a', href=True):\n",
    "    href = link['href']\n",
    "    link_text = link.get_text() \n",
    "    urls.append(href)\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "05e21d14-5730-42c0-9c8a-5945c4c26737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = []\n",
    "for link in soup.find_all('a', href=True):\n",
    "    href = link['href']\n",
    "    link_text = link.get_text() \n",
    "    if \"Apply\" in link_text and href.startswith(\"http\"):\n",
    "        urls.append(href)\n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e329e831-e344-47cb-8d04-f080e11df9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_listings = pd.DataFrame({'Job Title': jobs,'Location': jobs_company,'Date':job_time,'Apply_here':urls})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d615955-b2f0-4e85-ac83-c19ed634580d",
   "metadata": {},
   "source": [
    "b. Next, get those same urls in a different way. Examine the urls and see if you can spot the pattern of how they are constructed. \n",
    "Then, build the url using the elements you have already extracted. Ensure that the urls that you created match those that you extracted \n",
    "using BeautifulSoup. Warning: You will need to do some string cleaning and prep in constructing the urls this way. For example, \n",
    "look carefully at the urls for the \"Software Engineer (Python)\" job and the \"Scientist, research (maths)\" job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "fb43b114-7fa4-4871-b84f-1a443e4ae383",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_urls = []\n",
    "base_url='https://realpython.github.io/fake-jobs/jobs/'\n",
    "for job_id in range(100):\n",
    "    for job_title in jobs:\n",
    "        job_titles = job_title.lower().replace(' ', '-')\n",
    "        job_url = (base_url)+(job_titles)+('-0')+('.html')\n",
    "        new_urls.append(job_url)\n",
    "\n",
    "for url in new_urls:\n",
    "    len(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3fe9ae-4159-4e9e-a533-667ca390b5a3",
   "metadata": {},
   "source": [
    "base_urls = []\n",
    "base_url='https://realpython.github.io/fake-jobs/jobs/'\n",
    "for job_id in range(100):\n",
    "    for job_title in jobs:\n",
    "        job_titles = job_title.lower().replace(' ', '-')\n",
    "        job_url = f\"{base_url}{job_titles}-{job_id}.html\"\n",
    "        base_urls.append(job_url)\n",
    "\n",
    "for url in base_urls:\n",
    "    print(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea6483d-d7cf-4ef9-bfd3-03e76efa7574",
   "metadata": {},
   "source": [
    "3.Finally, we want to get the job description text for each job.\n",
    "a. Start by looking at the page for the first job, https://realpython.github.io/fake-jobs/jobs/senior-python-developer-0.html. Using BeautifulSoup, extract the job description paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4c0f1d57-8eac-4356-b93b-87ff8981bca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional asset web application environmentally friendly detail-oriented asset. Coordinate educational dashboard agile employ growth opportunity. Company programs CSS explore role. Html educational grit web application. Oversea SCRUM talented support. Web Application fast-growing communities inclusive programs job CSS. Css discussions growth opportunity explore open-minded oversee. Css Python environmentally friendly collaborate inclusive role. Django no experience oversee dashboard environmentally friendly willing to learn programs. Programs open-minded programs asset.\n"
     ]
    }
   ],
   "source": [
    "URL = 'https://realpython.github.io/fake-jobs/jobs/'\n",
    "response = requests.get(URL)\n",
    "job_url = 'https://realpython.github.io/fake-jobs/jobs/senior-python-developer-0.html'\n",
    "response = requests.get(job_url)\n",
    "soup = BS(response.text, 'html.parser')\n",
    "job_desc = soup.findAll('p')[1].get_text()\n",
    "print(job_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03090c0-6b99-4375-b574-5263c5670fdc",
   "metadata": {},
   "source": [
    "b. We want to be able to do this for all pages. Write a function which takes as input a url and returns the description text on that page. For example, if you input \"https://realpython.github.io/fake-jobs/jobs/television-floor-manager-8.html\" into your function, it should return the string \"At be than always different American address. Former claim chance prevent why measure too. Almost before some military outside baby interview. Face top individual win suddenly. Parent do ten after those scientist. Medical effort assume teacher wall. Significant his himself clearly very. Expert stop area along individual. Three own bank recognize special good along.\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e525b674-25f1-4b64-a60c-bd0ad62e10d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'At be than always different American address. Former claim chance prevent why measure too. Almost before some military outside baby interview. Face top individual win suddenly. Parent do ten after those scientist. Medical effort assume teacher wall. Significant his himself clearly very. Expert stop area along individual. Three own bank recognize special good along.'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def job_desc(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BS(response.text)\n",
    "    job_description = soup.find_all('p')[1].get_text()\n",
    "    return job_description  \n",
    "    \n",
    "url = 'https://realpython.github.io/fake-jobs/jobs/television-floor-manager-8.html'\n",
    "job_desc(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5819db28-5f01-4526-a369-d3dd2f0dc8d5",
   "metadata": {},
   "source": [
    "c. Use the .apply method on the url column you created above to retrieve the description text for all of the jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "60add928-5776-4769-a9bf-125eb1d410b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df = pd.DataFrame(job_listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "65d6dd57-1f33-4a7c-9bfe-fee4c01cd53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>Apply_here</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Python Developer</td>\n",
       "      <td>Payne, Roberts and Davis</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Energy engineer</td>\n",
       "      <td>Vasquez-Davidson</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Job Title                  Location        Date  \\\n",
       "0  Senior Python Developer  Payne, Roberts and Davis  2021-04-08   \n",
       "1          Energy engineer          Vasquez-Davidson  2021-04-08   \n",
       "\n",
       "                                          Apply_here  \n",
       "0  https://realpython.github.io/fake-jobs/jobs/se...  \n",
       "1  https://realpython.github.io/fake-jobs/jobs/en...  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b1e1561a-eb0f-41cb-9fca-6807743ac7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_listings['Job_description'] = job_listings['Apply_here'].apply(job_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "bb7c52cd-0198-4a86-ac02-0387e1240113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>Apply_here</th>\n",
       "      <th>Job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Python Developer</td>\n",
       "      <td>Payne, Roberts and Davis</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/se...</td>\n",
       "      <td>Professional asset web application environment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Energy engineer</td>\n",
       "      <td>Vasquez-Davidson</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/en...</td>\n",
       "      <td>Party prevent live. Quickly candidate change a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Legal executive</td>\n",
       "      <td>Jackson, Chambers and Levy</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/le...</td>\n",
       "      <td>Administration even relate head color. Staff b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fitness centre manager</td>\n",
       "      <td>Savage-Bradley</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/fi...</td>\n",
       "      <td>Tv program actually race tonight themselves tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Product manager</td>\n",
       "      <td>Ramirez Inc</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/pr...</td>\n",
       "      <td>Traditional page a although for study anyone. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Job Title                    Location        Date  \\\n",
       "0  Senior Python Developer    Payne, Roberts and Davis  2021-04-08   \n",
       "1          Energy engineer            Vasquez-Davidson  2021-04-08   \n",
       "2          Legal executive  Jackson, Chambers and Levy  2021-04-08   \n",
       "3   Fitness centre manager              Savage-Bradley  2021-04-08   \n",
       "4          Product manager                 Ramirez Inc  2021-04-08   \n",
       "\n",
       "                                          Apply_here  \\\n",
       "0  https://realpython.github.io/fake-jobs/jobs/se...   \n",
       "1  https://realpython.github.io/fake-jobs/jobs/en...   \n",
       "2  https://realpython.github.io/fake-jobs/jobs/le...   \n",
       "3  https://realpython.github.io/fake-jobs/jobs/fi...   \n",
       "4  https://realpython.github.io/fake-jobs/jobs/pr...   \n",
       "\n",
       "                                     Job_description  \n",
       "0  Professional asset web application environment...  \n",
       "1  Party prevent live. Quickly candidate change a...  \n",
       "2  Administration even relate head color. Staff b...  \n",
       "3  Tv program actually race tonight themselves tr...  \n",
       "4  Traditional page a although for study anyone. ...  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_listings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7fd648b3-ed1c-4590-91f3-a891e47491de",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_listings.to_csv('job_listings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c27ed3-73e8-4c91-b82d-bbcbef1ac291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11522c1-d731-4ece-ae95-8635c47369cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
